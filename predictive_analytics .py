# -*- coding: utf-8 -*-
"""predictive_analytics.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ziubbZ2ovuGifRKu9trersRuY4chXi6B
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
from matplotlib import pyplot as plt
import seaborn as sns
# %matplotlib inline

"""Dataset dari binance.me didapat menggunakan python binance"""

# load the dataset
df = pd.read_csv("bitcoin-binance.csv")
df.head()

len(df) # jumlah data

"""Deskripsi Variabel"""

df.info()

"""terdapat 1 column bertipe objek dan 5 column bertipe float, lalu tidak ada missing value"""

df.describe()

"""cek apakah ada outliners"""

numerical = [x for x in df.columns if x != 'Date']
plt.figure(figsize=(16,12))
sns.boxplot(data=df[numerical])
plt.show()

"""kolom low dan volume memiliki outliner, salah satu cara untuk menangani ouliners adalah dengan menggunakan IQR Method"""

Q1 = df.quantile(.25)
Q3 = df.quantile(.75)
IQR = Q3 - Q1
bottom = Q1 - 1.5 * IQR
top = Q3 + 1.5 * IQR
df = df[~((df < bottom) | (df > top)).any(axis=1)]
df.head()

"""Univariate Analysis"""

df[numerical].hist(bins=50, figsize=(20,15))
plt.show()

"""Multivariate Analysis"""

sns.pairplot(df[numerical], diag_kind = 'kde')

"""Data Preparation

drop kolom yang tidak perlu
"""

df = df.drop(['Date', 'Volume'], axis=1)
df.head()

"""Train-Test-Split"""

X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')
print(f'Total # of sample in train dataset: {len(y_train)}')
print(f'Total # of sample in test dataset: {len(y_test)}')

"""Standarisasi"""

from sklearn.preprocessing import MinMaxScaler
 
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

models = pd.DataFrame(columns=['train_mse', 'test_mse'], index=['RF', 'KNN', 'Boosting', 'SVR'])

"""Modeling dengan KNN"""

from sklearn.model_selection import GridSearchCV

def grid_search(model, hyperparameters):
  results = GridSearchCV(
      model,
      hyperparameters,
      cv=5,
      verbose=1,
      n_jobs=6
  )

  return results

from sklearn.neighbors import KNeighborsRegressor
from sklearn.metrics import mean_squared_error
 
knn = KNeighborsRegressor()
hyperparameters = {
    'n_neighbors': range(1, 10)
}
knn_search = grid_search(knn, hyperparameters)
knn_search.fit(X_train, y_train)

print(knn_search.best_params_)
print(knn_search.best_score_)

"""Modeling dengan Random Forest"""

from sklearn.ensemble import RandomForestRegressor
 
RF = RandomForestRegressor()
hyperparameters = {
    'bootstrap': [True],
    'max_depth': [80, 90, 100, 110],
    'max_features': [2, 3],
    'min_samples_leaf': [3, 4, 5],
    'min_samples_split': [8, 10, 12],
    'n_estimators': [100, 200, 300, 1000]
}
RF_search = grid_search(RF, hyperparameters)
RF_search.fit(X_train, y_train)

print(RF_search.best_params_)
print(RF_search.best_score_)

"""Modelling dengan Boosting Algorithm"""

from sklearn.ensemble import AdaBoostRegressor
 
boosting = AdaBoostRegressor()      
hyperparameters = {'learning_rate' : [0.1, 0.05, 0.01, 0.05, 0.001],
                   'n_estimators': [25, 50, 75, 100],
                   'random_state': [11, 33, 55, 77]
                } 
boosting_search = grid_search(boosting, hyperparameters)                      
boosting_search.fit(X_train, y_train)
print(boosting_search.best_params_)
print(boosting_search.best_score_)

"""Modelling dengan SVR """

from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error

svr= SVR()            
hyperparameters = {
    'kernel': ['rbf'],
    'C': [0.001, 0.01, 0.1, 10, 100, 1000],
    'gamma': [0.3, 0.03, 0.003, 0.0003]
}               
svr_search = grid_search(svr, hyperparameters)
svr_search.fit(X_train, y_train)
print(svr_search.best_params_)
print(svr_search.best_score_)

"""Model Training"""

knn = KNeighborsRegressor(n_neighbors= 4)
knn.fit(X_train, y_train)

RF = RandomForestRegressor(bootstrap= True, max_depth= 80, max_features= 2, min_samples_leaf= 3, min_samples_split= 8, n_estimators= 200)
RF.fit(X_train, y_train)

boosting = AdaBoostRegressor(learning_rate= 0.1, n_estimators= 100, random_state= 77)   
boosting.fit(X_train, y_train)

svr = SVR(C= 1000, gamma= 0.3, kernel= 'rbf')
svr.fit(X_train, y_train)

"""Evaluasi Model"""

model_dict = {
    'RF': RF,
    'KNN': knn,
    'Boosting': boosting,
    "SVR": svr
}

for name, model in model_dict.items():
  models.loc[name, 'train_mse'] = mean_squared_error(y_train, model.predict(X_train))
  models.loc[name, 'test_mse'] = mean_squared_error(y_test, model.predict(X_test))

models.head()

models.sort_values(by='test_mse', ascending=False).plot(kind='bar', zorder=3)

"""Menguji 4 algoritma"""

prediksi = X_test[:1].copy()
pred_dict = {'y_true':y_test[:1]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)
 
pd.DataFrame(pred_dict)